{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot_face_recognition.py\n",
    "## Faces recognition example using eigenfaces and SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "    # Arguments\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "def extract_data(min_faces_per_person):\n",
    "    # #############################################################################\n",
    "    # Download the data, if not already on disk and load it as numpy arrays\n",
    "\n",
    "    lfw_people = fetch_lfw_people(min_faces_per_person=min_faces_per_person, resize=0.4)\n",
    "\n",
    "    # introspect the images arrays to find the shapes (for plotting)\n",
    "    n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "    # for machine learning we use the 2 data directly (as relative pixel\n",
    "    # positions info is ignored by this model)\n",
    "    X = lfw_people.data\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    # the label to predict is the id of the person\n",
    "    y = lfw_people.target\n",
    "    target_names = lfw_people.target_names\n",
    "    n_classes = target_names.shape[0]\n",
    "\n",
    "    print(\"Total dataset size:\")\n",
    "    print(\"n_samples: %d\" % n_samples)\n",
    "    print(\"n_features: %d\" % n_features)\n",
    "    print(\"n_classes: %d\" % n_classes)\n",
    "\n",
    "\n",
    "    # #############################################################################\n",
    "    # Split into a training set and a test set using a stratified k fold\n",
    "\n",
    "    # split into a training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, h, w, n_classes, target_names\n",
    "\n",
    "def pca(X_train, X_test, h, w, n_components):\n",
    "\n",
    "    # #############################################################################\n",
    "    # Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "    # dataset): unsupervised feature extraction / dimensionality reduction\n",
    "\n",
    "    print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "          % (n_components, X_train.shape[0]))\n",
    "    t0 = time()\n",
    "    pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "              whiten=True).fit(X_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "    print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "    t0 = time()\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    return X_train_pca, X_test_pca, eigenfaces\n",
    "\n",
    "def svm(X_train_pca, y_train, X_test_pca, y_test, n_classes, target_names):\n",
    "    # #############################################################################\n",
    "    # Train a SVM classification model\n",
    "\n",
    "    print(\"Fitting the classifier to the training set\")\n",
    "    t0 = time()\n",
    "    param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "    clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),\n",
    "                       param_grid, cv=5, iid=False)\n",
    "    clf = clf.fit(X_train_pca, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "    # #############################################################################\n",
    "    # Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "    print(\"Predicting people's names on the test set\")\n",
    "    t0 = time()\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.1 - Understanding SVMs and hyperparameters\n",
    "## Support Vector Machine and hyperparameters\n",
    "Super Vector Machine (SVM) is a machine learning model that is used both for classification and regression. \n",
    "The objective of the SVM algorithm is to find an hyperplane to separate data of distinct classes. Choose how to separate this classes is possible changing the hyperparameters of the SVM.\n",
    "The main hyperparameters of a SVM are:\n",
    "- **Kernel**: kernel parameters selects the type of hyperplane used to separate the data. Using ‘linear’ will use a linear hyperplane (a line in the case of 2D data). ‘rbf’ and ‘poly’ uses a non linear hyperplane.\n",
    "\n",
    "- **C**: is the Cost parameter of the error term. It controls the trade off between smooth decision boundary and classifying training points correctly. A large value of C means you will get more intricate decision curves trying to fit in all the points. This may lead to overfitting.\n",
    "\n",
    "- **Gamma**: defines how far the influence of a single training example reaches. If the value of Gamma is high, then the decision boundary will depend on points close to the decision boundary. If the value of Gamma is low, then far away points carry more weights than nearer points and thus the decision boundary becomes more like a straight line.\n",
    "\n",
    "The value of gamma and C should not be very high because it leads to the overfitting and it shouldn’t be very small (underfitting). Thus we need to choose the optimal value of C and Gamma in order to get a good fit.\n",
    "\n",
    "## Grid Search and best set of hyperparameters\n",
    "Grid search is the process of performing hyperparameter tuning in order to determine the optimal hyperparameter values.\n",
    "\n",
    "This is a python code snippet of grid search using GridSearchCV of the \"sklearn\" library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "print(\"Finding best set of hyperparameter\")\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),\n",
    "                   param_grid, cv=5, iid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter of GridSearchCV is the **estimator** that requires the kernel used for the hyperparameter tuning process (in this case an 'rbf' kernel is used).\n",
    "The **param_grid** parameter requires a list of parameters and the range of values for each parameter of the specified estimator.\n",
    "The GridSearchCV function search for the best set of hyperparameters performing a cross validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then is possible to use the best set of hyperparameter values, chosen in the grid search, for fitting training data."
   ]
  },
  {
   "attachments": {
    "variance_face.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the selection of features changes the results of the system\n",
    "Feature extraction is a process of dimensionality reduction by which an initial set of raw data is reduced to more manageable groups for processing. In this lecture it is used the Principal Component Analysis (PCA).\n",
    "### Number of components\n",
    "Using the PCA approach, is important to estimate how many components are needed to describe the data. This can be done by looking at the cumulative variance of these components to see how much of the data information the projection is preserving. In our face recognition example we have more than 3.000 components, looking at the cumulative variance of the first 150 components we see that these 150 components account for just over 90% of the variance [1]. This means that using these 150 components, we would recover most of the essential characteristics of the data.\n",
    "\n",
    "![variance_face.png](attachment:variance_face.png) image from *Python Data Science Handbook* [1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the PCA on the whole dataset containing images of many more persons\n",
    "In our example we take from the dataset the picture of the persons for which we have more than 70 faces. Decreasing this parameter, will lead to have a more large dataset with more person, but for each person we have few images. This leads to a decreasing accurance in the face recognition process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Below is possible to execute the lecture example with different **#n_components** and **#min_face_per_person**. Looking at the result grids is possible to see how decreasing the #components and the #min_face_per_person (incresing number of faces) decreas the face recognition accurance. Decreasing the #min_face_per_person we have more images for the training process but for the person for which we have few faces, the prediction is less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **n_components=150** **min_faces_per_person=70**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#n_components = 150\")\n",
    "print(\"#min_faces_per_person = 70\")\n",
    "n_components = 150\n",
    "min_faces_per_person = 70\n",
    "X_train, X_test, y_train, y_test, h, w, n_classes, target_names = extract_data(min_faces_per_person)\n",
    "X_train_pca, X_test_pca, eigenfaces = pca(X_train, X_test, h, w, n_components)\n",
    "svm(X_train_pca, y_train, X_test_pca, y_test, n_classes, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **n_components=150** **min_faces_per_person=30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#n_components = 150\")\n",
    "print(\"#min_faces_per_person = 30\")\n",
    "n_components = 150\n",
    "min_faces_per_person = 30\n",
    "X_train, X_test, y_train, y_test, h, w, n_classes, target_names = extract_data(min_faces_per_person)\n",
    "X_train_pca, X_test_pca, eigenfaces = pca(X_train, X_test, h, w, n_components)\n",
    "svm(X_train_pca, y_train, X_test_pca, y_test, n_classes, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **n_components=30** **min_faces_per_person=70**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#n_components = 30\")\n",
    "print(\"#min_faces_per_person = 70\")\n",
    "n_components = 30\n",
    "min_faces_per_person = 70\n",
    "X_train, X_test, y_train, y_test, h, w, n_classes, target_names = extract_data(min_faces_per_person)\n",
    "X_train_pca, X_test_pca, eigenfaces = pca(X_train, X_test, h, w, n_components)\n",
    "svm(X_train_pca, y_train, X_test_pca, y_test, n_classes, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **n_components=75** **min_faces_per_person=45**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#n_components = 75\")\n",
    "print(\"#min_faces_per_person = 45\")\n",
    "n_components = 75\n",
    "min_faces_per_person = 45\n",
    "X_train, X_test, y_train, y_test, h, w, n_classes, target_names = extract_data(min_faces_per_person)\n",
    "X_train_pca, X_test_pca, eigenfaces = pca(X_train, X_test, h, w, n_components)\n",
    "svm(X_train_pca, y_train, X_test_pca, y_test, n_classes, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.2 - Learning Features as an Input for Classification\n",
    "## Autoencoder ( 2 layers)\n",
    "The feature extraction part of the approach (PCA) should be replaced. I'll use the **latent space** of a 2 layers  autoencoder trained in an unsupervised fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "x = lfw_people.data\n",
    "y = lfw_people.target\n",
    "\n",
    "x_train_orig, x_test_orig, y_train_orig, y_test_orig = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "original_dim = h * w\n",
    "\n",
    "idx = np.arange(x_train_orig.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "x_train = np.zeros(shape=(x_train_orig.shape[0], x_train_orig.shape[1]))\n",
    "y_train = np.zeros(shape=(x_train_orig.shape[0],))\n",
    "for i in range(0, x_train_orig.shape[0]):\n",
    "    x_train[i] = x_train_orig[ idx[i] ]\n",
    "    y_train[i] = y_train_orig[ idx[i] ]\n",
    "\n",
    "idx = np.arange(x_test_orig.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "x_test = np.zeros(shape=(x_test_orig.shape[0], x_test_orig.shape[1]))\n",
    "y_test = np.zeros(shape=(x_test_orig.shape[0],))\n",
    "for i in range(0, x_test_orig.shape[0]):\n",
    "    x_test[i] = x_test_orig[ idx[i] ]\n",
    "    y_test[i] = y_test_orig[ idx[i] ]\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "intermediate_dim = 512\n",
    "batch_size = 100\n",
    "latent_dim = 150\n",
    "epochs = 50\n",
    "\n",
    "inputs = Input(shape=(original_dim,))\n",
    "\n",
    "latent_space = Dense(latent_dim, activation='relu')(input)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(inputs, latent_space, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "output = Dense(original_dim, activation='sigmoid')(latent_space)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "# end-to-end autoencoder\n",
    "vae = Model(inputs, output, name=\"vae\")\n",
    "vae.compile(optimizer='Adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "vae.summary()\n",
    "\n",
    "print(\"Training the autoencoder to the training set\")\n",
    "vae.fit(x_train, x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))\n",
    "\n",
    "\n",
    "x_train_latentspace = encoder.predict(x_train, batch_size)\n",
    "x_test_latentspace = encoder.predict(x_test, batch_size)\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'C': [1, 5, 10, 1e2, 5e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 0.5], }\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),\n",
    "                   param_grid, cv=5, iid=False)\n",
    "clf = clf.fit(x_train_latentspace, y_train)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(x_test_latentspace)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational autoencoder\n",
    "The feature extraction part of the approach (PCA) should be replaced. I'll use the **latent space** of a variational autoencoder trained in an unsupervised fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from dataset\n",
    "min_faces_per_person = 70\n",
    "x_train, x_test, y_train, y_test, h, w, n_classes, target_names = extract_data(min_faces_per_person)\n",
    "\n",
    "#Prepare dataset\n",
    "original_dim = h * w\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "#Layers dimension\n",
    "#Latent space dimension is 150 as request from the exercise\n",
    "intermediate_dim = 512\n",
    "latent_dim = 150\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the **encoder** network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "inputs = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)\n",
    "z = Lambda(sampling, output_shape=(latent_dim, ), name='z')([z_mean, z_log_sigma])\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(inputs, [z_mean, z_log_sigma, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the **decoder** network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(latent_dim,))\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')(encoded_input)\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')(decoder_h)\n",
    "\n",
    "# decoder, from latent space to outputs\n",
    "decoder = Model(encoded_input, decoder_mean, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the **autoencoder**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "\n",
    "# end-to-end autoencoder\n",
    "vae = Model(inputs, outputs, name=\"vae\")\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss, metrics=[\"accuracy\"])\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the **autoencoder**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained network. We'll use the encoder network as the feature extracion part. Last, train the Support Vector Machine with the provided features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_latentspace, _, _ = encoder.predict(x_train, batch_size)\n",
    "x_test_latentspace, _, _ = encoder.predict(x_test, batch_size)\n",
    "\n",
    "svm(x_train_latentspace, y_train, x_test_latentspace, y_test, n_classes, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results to the original approach \n",
    "The results obtained using the encoder network are not the expected one. Every faces is associated to Hugo Chavez. This is a bad result, probably due to an incorrect implementation of the autoencoder. It seems the network is not trained well but I can't find out where is the problem in my code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
